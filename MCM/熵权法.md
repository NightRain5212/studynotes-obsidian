
- 熵权法(*EWM,Entropy Weight Method*)是一种用于确定多指标评价体系中各指标权重的方法。其基本思想是利用信息熵来量化各指标的信息含量
- 在**层次分析法和Topsis法中权重都是主观因素**得到的，而熵权法是一种较为客观的方法。
- 它能够客观反映数据的内在特征，减少人为因素对权重设定的影响。适用于多指标决策分析，如综合评价和排序问题。

### 基本概念

- 熵：系统无序程度的一个度量。
- 信息熵：用来判断某个指标的离散程度，信息熵值越小，指标的离散程度越大。
- 原理：指标的离散程度越小，反应的信息量也越小，对应的权值越低。


### 熵权法的步骤如下：

- **数据标准化**：
	- 将原始数据进行标准化处理，以消除不同指标之间的量纲影响。
- **计算各指标的熵值**：
    - 计算每个指标在各评价对象下的比重。
    - 根据比重计算各指标的熵值。
- **计算熵冗余度**：
	- 熵冗余度反映了指标信息的有效性。信息量越大，熵冗余度越高。
- **确定指标权重**：
	- 根据熵冗余度为各指标分配权重。冗余度越大的指标，其权重越高，表示该指标对整体评价的贡献越大。

### 数据正向化

- 详见Topsis页

### 数据标准化

- $z_{ij} = \frac{x_{ij}}{\sqrt{\sum_{i=1}{n}{x_{ij}^2}}}$
- $z_{ij} = \frac{x_{ij} - min\{x_j\}}{max\{x_j\} - min\{x_j\}}$
- 其中$min\{x_j\}$表示第$j$列元素的最小值,$max\{x_j\}$表示第$j$列元素的最大值

### 计算概率矩阵

- $p_{ij} = \frac{z_{ij}}{\sum_{i-1}^{n}{z_{ij}}}$
- 计算同一指标中，某一样本所占的比重。

### 计算熵值

- $e_j = -\frac{1}{ln(n)} \sum_{i=1}^{n}{p_{ij}} ln(p_{ij})$
- 其中n为评价对象的数量

### 计算熵冗余度

- $d_j=1-e_j$
- 熵冗余度越大，说明信息效用越大

### 确定权重

- $w_j = \frac{d_j}{\sum_{i=1}^{m}{d_{j}}}$

### 计算综合评分

- $S_j = \sum_{i=1}^{m} w_j\times z_{ij}$

### 示例代码

```python
import numpy as np

# 原始数据矩阵 (已经正向化)
data = np.array([
    [9,0,0,0],
    [8,3,0.9,0.5],
    [6,7,0.2,1]
])

# 自定义取对数函数（考虑数据为0的情况）
def mlog(x):
    l = len(x)
    res = []
    for i in x:
        if i == 0:
            res.append(0)
        else:
            res.append(np.log(i))
    return np.array(res)


# 标准化矩阵
Z = data / np.sqrt(np.sum(data*data,axis=0))
print("标准化矩阵为：",Z)

# 计算概率矩阵
P = Z / np.sum(Z,axis=0)

# 计算熵值和熵冗余度
n,m = P.shape # 获取p的行数，列数
d = []
for i in range(m):
    x = P[:,i] # 获取第i列的元素
    e = -np.sum(x*mlog(x))/np.log(n) # 计算熵值
    d.append(1-e) # 计算熵冗余度
d = np.array(d)
# 确定权重
w = d/np.sum(d)
print("权重为:",w)
# 计算评分
s = np.dot(Z,np.reshape(w,(-1,1)))
for i in s:
    print("各评分为：",i)
```