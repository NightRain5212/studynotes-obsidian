
- AHP(*Analytic Hierarchy Process*)是对一些较为复杂，较为模糊的问题作出决策的简易方法，适用于**难以完全定量分析**的问题。
- 是对于评价决策类问题的处理策略

#### 模型原理

- 首先把问题条理化，层次化，构造出有层次的结构模型。
	- 目标层(最高层)：只有一个元素，是分析问题的**预定目标或理想结果**。
	- 准则层(中间层)：包含**实现目标所涉及的中间环节**，可以由若干个层次组成。
	- 方案层(最底层)：包含为实现目标可供选择的**各种措施，决策方案**等。
- 基本步骤：
	- 建立递阶层次结构模型
	- 构造各层次所有的判断矩阵
	- 一致性检验
	- 求权重然后评价

#### 构造判断矩阵

- 对指标的重要性两两比较，构造判断矩阵，从而科学求出权重.
- 矩阵中元素 $a_{i,j}$ 表示第 $i$ 个指标对(比)第 $j$ 个指标的重要程度.
- 重要程度的数字化：取值为 $[1,9]$ 中的整数，1表示同样重要，比另一因素更重要的程度数字越大，就越更加重要。
- 使用1到9的尺度进行评分：
	- 1：两者同等重要
	- 3：一者稍微重要于另一者
	- 5：一者明显重要于另一者
	- 7：一者强烈重要于另一者
	- 9：一者极端重要于另一者
- 不难得出，反过来的重要程度 $a_{j,i}= \frac{1}{a_{i,j}}$  .
- 若亮亮独立比较可能会导致矛盾，所以需要一致性检验

#### 一致性检验

- 若$a_{i,j} = a_{i,k}\times a_{k,j}$ 且矩阵各行列成倍数关系，则该矩阵是**一致矩阵**，不会出现矛盾。
- 检验构造的判断矩阵和一致矩阵是否有太大差别（一定误差可容忍）

#### 一致矩阵

- 矩阵中每个元素满足 $a_{i,j}>0$ 且 $a_{i,j}\times a_{j,i} = 1$ 则该矩阵为正互反矩阵。
- 若正互反矩阵满足$a_{i,k} \times a_{k,j} = a_{i,j}$ ,则为一致矩阵。

#### 引理

- A为n阶方阵，且r(A)=1，则A有一个特征值为tr(A),其余特征值为0。
- tr(A)为A的迹，是A对角线元素的和。构造的判断矩阵的迹即为n。
- 一致矩阵的秩一定为1
- 特征值为n时，对应的特征向量为$k[\frac{1}{a_{11}},\frac{1}{a_{12}},\dots,\frac{1}{a_{1n}}]^{T}$ 
- 当n阶正互反矩阵A为一致矩阵时，当且仅当最大特征值$\lambda_{max} = n$,且当正互反矩阵A非一致矩阵时，$\lambda_{max} > n$ ,判断矩阵越不一致时，最大特征值越大。

#### 一般步骤

- 计算一致性指标CI
	- $CI = \frac{\lambda_{max} - n}{ n - 1}$ 
- 查找对应的平均随机一致性指标RI
	- 只需查表即可，无需计算
- 计算一致性比例CR
	- $CR = \frac{CI}{RI}$
	- CR = 0 ,则该矩阵为一致矩阵。
	- CR < 0.1 ,则判断矩阵一致
	- CR > 0.1 ,判断矩阵不一致
- 特征值可以用matlab计算，特征值有虚数则比较模长（将模长赋给$\lambda_{max}$）

#### 求权重

##### 算术平均法

- 将判断矩阵按照列归一化（每一个元素）
- 将归一化后每一行的元素相加，得到一个向量
- 将得到的向量的各个元素除以n即可得到权重向量。
- $W_i = \frac{1}{n} \sum_{n}^{i=1}{\frac{a_{ij}}{\sum_{n}^{k=1}{a_{kj}}}}$

##### 几何平均法

- 将矩阵的元素按行相乘，得到一个新的向量。
- 将新的向量每个元素开n次方。
- 最后对这个向量进行归一化，即可得到权重向量。
- $W_i = \frac{(\prod_{j=1}^{n}{a_{ij}})^{\frac{1}{n} }}{\sum_{k=1}^{n}({\prod_{j=1}^{n}{a_{kj}}})^{\frac{1}{n}}}$

##### 特征值法

- 求出矩阵的最大特征值，以及对应的特征向量。
- 对求出的特征向量归一化就立刻得到权重。

#### 求评分

- 最后由权重求出最终的评分即可。

#### 归一化处理

- 目的
	- 将有量纲转化为无量纲，同时将数据归一化至同一量级，解决数据间的可比性问题。
- 方法一
	- 将指标数组$[a_1,\space a_2,\space \dots ,\space a_n]$ 加权归一化处理得到 $\frac{p_1a_1}{\sum_{i=1}^{n}{a_i} } \space ,\frac{p_2a_2}{\sum_{i=1}^{n}{a_i} }\space \dots\space \frac{p_na_n}{\sum_{i=1}^{n}{a_i} }$
-  **最小-最大归一化（Min-Max Normalization）** ：
	- 这种方法将数据缩放到一个特定的区间，通常是$[0, 1]$或$[-1, 1]$。其公式为：$x′=\frac{x-min}{max-min}$​，其中x是原始数据，min和max分别是该特征的最小值和最大值。
    
- **Z-score归一化（Z-score Normalization）** ：
	- 也称为标准差归一化，该方法通过减去均值并除以标准差来将数据转换为均值为0、标准差为1的分布。其公式为：$x'=\frac{x-\mu}{\sigma}$，其中μ是均值，σ是标准差。
    
-  **小数定标规范化（Decimal Scaling）** ：
	- 这种方法通过移动数据的小数点来缩放数据，直到所有的数值都在-1到1之间。其公式为：$x'=\frac{x}{10^j}$，其中$j$是使得$x'$在$[-1, 1]$范围内的最小整数。
    
- **对数归一化（Log Normalization）** ：
	- 适用于具有正偏态分布的数据，通过取对数来减少数据的偏斜性。其公式为：$x′=log⁡(x+1)$，其中加1是为了避免取对数时出现负数的情况。
    
- **反余切函数归一化（Arc-cot Normalization）** ：
	- 这种方法适用于将数据映射到$[-1, 1]$区间，其公式为：$x′=2arccot(e^{\frac{x-m}{s}})$，其中m是均值，s是标准差

#### 示例代码

```python
import numpy as np

# 导入判断矩阵
A = np.array([[1,2,3,5],[1/2,1,1/2,2],[1/3,2,1,2],[1/5,1/2,1/2,1]])

# 获取矩阵的行数，1为列数
n = A.shape[0]

# 求最大的特征值及特征向量
eig_val,eig_vec = np.linalg.eig(A)
max_eig = max(eig_val)

# 计算CR
CI = (max_eig - n)/(n-1)
RI = [0,0.0001,0.52,0.89,1.12,1.36,1.41,1.46,1.49,1.52,1.54,1.56,1.58,1.59]
# n=2时，一定是一致矩阵，CI=0，为避免分母为0，将第二个元素改为接近0的数
CR = CI/RI[n-1]
print(CR)

# 求权重
# 算数平均法
# axis参数决定按行求和还是按列求和。0表示按列求和，1表示按行求和
A_sum = np.sum(A,axis=0)
# 归一化
Stand_A = A/A_sum
# 将归一化的数组按行求和
Asumr = np.sum(Stand_A,axis=1)
# 求出权重向量
weights = Asumr/n

# 几何平均法
# 将矩阵按行逐元素相乘
prodA = np.prod(A,axis=1)
# 将得到的向量开n次方
prodnA = np.power(prodA,1/n)
# 归一化
weights1 = prodnA/np.sum(prodnA)

# 特征值法

eig1,eig2 = np.linalg.eig(A)
# 找出最大值的索引
maxindex = np.argmax(eig1)
# 找出对应的特征向量
maxv = eig2[:,maxindex]
# 归一化
weights2 = maxv/np.sum(maxv)
print(weights2)
```
